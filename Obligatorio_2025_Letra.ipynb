{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio - Taller Agentes Inteligentes 2025\n",
    "\n",
    "En este trabajo obligatorio aplicaremos los conceptos vistos en el curso para diseñar, implementar y evaluar agentes capaces de aprender a jugar al clásico **Breakout** de Atari, utilizando el entorno provisto por Farama Gymnasium ([https://ale.farama.org/environments/breakout/](https://ale.farama.org/environments/breakout/)). \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/oMxHgRrISJsAAAAM/atari-deep-learning.gif\" alt=\"Atari Deep Learning\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "El ejercicio se enmarca en un contexto de aprendizaje práctico, donde trabajaremos con las interfaces estándar de Gymnasium para:\n",
    "\n",
    "1. **Profundizar en algoritmos de valor**: implementaremos y compararemos dos variantes de Q-Learning basadas en redes neuronales profundas:\n",
    "   * **Deep Q Learning (DQN)**\n",
    "   * **Double Deep Q Learning (DDQN)**\n",
    "2. **Evaluar rendimiento y estabilidad**: registraremos las recompensas obtenidas durante el entrenamiento de cada agente y analizaremos su comportamiento mediante gráficas comparativas.\n",
    "3. **Demostrar resultados de forma visual**: capturaremos vídeos que muestren a cada agente “resolviendo” el entorno, entendido como la habilidad de romper al menos cinco bloques en una partida.\n",
    "\n",
    "Debido a las limitaciones de tiempo y cómputo propias de un entorno de curso, no se espera entrenar modelos durante más de diez horas por agente. Por ello, será fundamental:\n",
    "\n",
    "* Integrar puntos de **checkpoint** para guardar periódicamente los pesos de la red.\n",
    "* Seguir en los puntos 2 y 3 la arquitectura y técnicas originales propuestas en los papers seminales de DQN y DDQN, dejando la experimentación adicional para el punto extra.\n",
    "* Flexibilizar la notebook de guía: pueden reorganizarla o dividirla en múltiples archivos según su conveniencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos y tareas\n",
    "\n",
    "1. **Completar la implementación**\n",
    "   * Rellenar el código faltante en la notebook y en los módulos auxiliares para que los agentes puedan interactuar con el entorno de Breakout.\n",
    "2. **Entrenar agentes**\n",
    "   * Ajustar y entrenar un **DQN** que alcance la condición de “resolver” (romper ≥ 10 bloques).\n",
    "   * Ajustar y entrenar un **DDQN** con la misma meta de desempeño.\n",
    "3. **Visualizar y analizar resultados**\n",
    "   * Generar **gráficas comparativas** de las recompensas obtenidas por ambos agentes en el mismo entorno (una gráfica por ambiente). Además se sugiere gráficas que muestren el valor de la función de valor Q para cada agente.\n",
    "   * Extraer **al menos dos conclusiones** por gráfica, comentando diferencias en convergencia, estabilidad y comportamiento exploratorio.\n",
    "4. **Registro de demostraciones**\n",
    "   * Grabar y entregar un **video demostrativo** de cada agente resolviendo el entorno.\n",
    "5. **Experimentación**\n",
    "   * Probar otras arquitecturas, técnicas de mejora o módulos de procesamiento de entradas más avanzados, documentando brevemente su impacto/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de evaluación\n",
    "\n",
    "| Criterio                                  | Descripción                                                  | Peso |\n",
    "| ----------------------------------------- | ------------------------------------------------------------ | ---- |\n",
    "| **Implementación y rendimiento**          | DQN y DDQN completados; cada agente rompe ≥ 10 bloques       | 40%  |\n",
    "| **Estructura y narrativa de la notebook** | Secciones claras, explicación de decisiones, “historia”      | 20%  |\n",
    "| **Análisis de resultados**                | Gráficas comparativas; ≥ 2 conclusiones por gráfico          | 20%  |\n",
    "| **Presentación visual**                   | Vídeos demostrativos de cada agente                          | 10%  |\n",
    "| **Experimentación**                       | Experimentación adicional documentada y analizada brevemente | 10%  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "\n",
    "* **Mnih, V.**, Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., … Hassabis, D. (2013). *Playing Atari with Deep Reinforcement Learning*. [arXiv:1312.5602](https://arxiv.org/abs/1312.5602)\n",
    "* **van Hasselt, H.**, Guez, A., & Silver, D. (2015). *Deep Reinforcement Learning with Double Q-learning*. [arXiv:1509.06461](https://arxiv.org/abs/1509.06461)\n",
    "* **Sutton, R. S.**, & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.), capítulo 16.5: “Human-level Video Game Play”. MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gc6t9etEt9I2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cwHCw6PMt9I3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import gymnasium\n",
    "import ale_py\n",
    "from utils import make_env, show_observation_stack\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALE (Atari Learning Environment) es un entorno de aprendizaje para videojuegos de Atari. En este caso, utilizaremos el entorno de Breakout. Es necesario entender que se separa el entorno de los roms de Atari, que son los juegos en sí. El entorno de ALE permite interactuar con los juegos de Atari a través de una API estándar, facilitando la implementación de algoritmos de aprendizaje por refuerzo.\n",
    "\n",
    "Debemos instalar los roms por separado, para ello primero tenemos que saber donde están los roms de Atari. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\ale_py\\roms\n"
     ]
    }
   ],
   "source": [
    "gymnasium.register_envs(ale_py) # registramos todos los entornos de ale_py\n",
    "ruta_init = ale_py.roms.__file__ # debemos saber donde se encuentra la carpeta roms\n",
    "ALE_ROMS_PATH = os.path.dirname(ruta_init)\n",
    "print(ALE_ROMS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar los siguientes comando para instalar los roms y colocalos en la carpeta correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"autorom[accept-rom-license]\"\n",
    "#!AutoROM --accept-license --install-dir {ALE_ROMS_PATH}\n",
    "#Lo hice por fuera por que en la colab no funcionaba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos la semilla para que los resultados sean reproducibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True # https://discuss.pytorch.org/t/what-is-the-differenc-between-cudnn-deterministic-and-cudnn-benchmark/38054\n",
    "torch.backends.cudnn.benchmark=True # https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936/4\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que dispositivo tenemos, si es GPU, MPS o CPU. **El uso de GPU es altamente recomendable** para acelerar el entrenamiento de los modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Algunas constantes\n",
    "\n",
    "# definimos el dispositivo que vamos a usar\n",
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando Atari\n",
    "\n",
    "Para reproducir fielmente el enfoque de Mnih et al. (2013) y reducir la carga computacional al trabajar con imágenes de Atari (210 × 160 píxeles, 128 colores), aplicamos el siguiente preprocesado φ a las últimas **4** frames del entorno:\n",
    "\n",
    "1. **Conversión a escala de grises**\n",
    "   Eliminamos la información de color (GRAYSCALE = True), pues la luminosidad es suficiente para capturar la dinámica de juego y reduce drásticamente la dimensionalidad de la entrada.\n",
    "\n",
    "2. **Down-sampling y recorte**\n",
    "   * Redimensionamos la imagen original a 110 × 84 píxeles, manteniendo la proporción horizontal.\n",
    "   * Recortamos un área central de 84 × 84 píxeles que contiene la “zona de juego”, descartando bordes innecesarios.\n",
    "     Este paso (SCREEN_SIZE = 84) no solo concentra la atención del modelo en la región relevante, sino que también garantiza un tamaño cuadrado compatible con las implementaciones de convoluciones en GPU.\n",
    "\n",
    "3. **Saltos temporales (frame skipping)**\n",
    "   Procesamos cada 4 frames (SKIP_FRAMES = 4), repitiendo la misma acción durante esos pasos. Esto reduce la redundancia temporal, acelera el entrenamiento y mantiene la coherencia del movimiento de la paleta y la bola.\n",
    "\n",
    "4. **Apilamiento de frames**\n",
    "   Finalmente, acumulamos las últimas 4 imágenes preprocesadas (NUM_STACKED_FRAMES = 4) en un único tensor de entrada. Así el agente puede inferir la velocidad y dirección de los elementos móviles a partir de la diferencia entre frames.\n",
    "\n",
    "Este esquema de preprocesado es fundamental para disminuir el espacio de entrada, acelerar las convoluciones y proporcionar al Q-net una representación compacta y rica en información dinámica, tal como se describe en el algoritmo 1 del paper original .\n",
    "\n",
    "> Se recomienda ver el método `make_env` en el archivo `utils.py` para entender cómo se implementa este preprocesado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAY_SCALE = True # si True, convertimos la imagen a escala de grises\n",
    "SCREEN_SIZE = 84 # redimensionamos a SCREEN_SIZExSCREEN_SIZE\n",
    "NUM_STACKED_FRAMES = 4 # apilamos NUM_STACKED_FRAMES frames\n",
    "SKIP_FRAMES = 4 # saltamos SKIP_FRAMES frames (haciendo la misma acción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loVxQPrwt9I5",
    "outputId": "18b7ed97-88dd-4b1e-a2cc-b2636686bfc7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGgCAYAAAAD9NhnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIhRJREFUeJzt3X9s1dX9x/HXFeTSQns3UO5ttWDZ6lAKA0GZhdguShckRoNxCv7A4BYQUCqZxYqJV4K3yDbSbUwcxGENqxgnOnRTW3XWH42zQ6tdmaCzg0571+DqvRVqG+j5/mH4fP30VuG2t5ze9vlITuLnfM793HePpK+cfn55jDFGAABYcJrtAgAAQxchBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwpt9C6MEHH1R2drZGjhypGTNm6LXXXuuvrwIAJKnh/XHQxx9/XEVFRXrwwQc1e/Zs/e53v9O8efO0d+9ejR8//hs/29XVpU8++URpaWnyeDz9UR4AoB8ZY9TW1qbMzEyddtoJ1jqmH1x00UVm2bJlrr5JkyaZu+6664SfbWpqMpJoNBqNluStqanphL/zE/7nuM7OTu3Zs0eFhYWu/sLCQtXU1MSM7+joUDQadZrhod4AMCikpaWdcEzCQ+jQoUM6duyY/H6/q9/v9yscDseMLy0tlc/nc9qJ/lwHAEgOJ3NKpd8uTOj+5caYHgsqKSlRJBJxWlNTU3+VBAAYYBJ+YcIZZ5yhYcOGxax6WlpaYlZHkuT1euX1ehNdBgAgCSR8JTRixAjNmDFDVVVVrv6qqirl5eUl+usAAEmsXy7RXr16tW688UbNnDlTF198sbZu3aqDBw9q2bJl/fF1AIAk1S8hdO211+rTTz/VunXr1NzcrNzcXP3lL3/RhAkT+uPrAABJymMG2DXR0WhUPp/PdhlJKxAIxPT961//+sbP1NXVnfC4kydPjuk7/fTTXduzZ88+4bGfeOIJ1/bll18e85nuF6d8+umnMWO6/5zdt3//+9/HfOa2225zbc+bNy9mzB//+EfX9pEjR1zb+/fvj/nMsGHDXNtTpkyJGdPdqFGjTjhmICkpKXFt33PPPTFjuv9/6s1FRu+//35M3y233BL3cQa63/zmN67tJUuWxIxZv369a7u0tLRfa+oPkUhE6enp3ziGZ8cBAKwhhAAA1hBCAABr+uXCBCSXns7ldNfTeaWezj8lwgMPPODa3r59e8yYkzlHkQjdzwH1NFfd5+FE5+AGq+7ncx577LG4j3Ho0KFElYMkwUoIAGANIQQAsIYQAgBYQwgBAKzhwgQAJ/Tcc8+5tnt6LcvJyM3NdW13f5RXTzdOP/PMM736LiQHVkIAAGsIIQCANYQQAMAazglBb7zxxgnHjB079hRU8qU1a9a4tn/yk5/EjOmvG2W7O/fcc13bPc1V9weYDkbTp093bff0/+RknOhhlhh6WAkBAKwhhAAA1hBCAABrBuxL7aZMmTIk/tYOAIPNsWPHVF9fz0vtAAADGyEEALCGEAIAWEMIAQCsGbA3q1ZWVnJjGwAkoWg0qoyMjJMay0oIAGANIQQAsIYQAgBYQwgBAKwhhAAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYE3cIvfrqq7riiiuUmZkpj8ejp59+2rXfGKNgMKjMzEylpKSooKBADQ0NiaoXADCIxB1Chw8f1ve//31t3ry5x/0bN27Upk2btHnzZtXW1ioQCGju3Llqa2vrc7EAgMEl7qdoz5s3T/PmzetxnzFGZWVlWrt2rRYsWCBJKi8vl9/vV0VFhZYuXdq3agEAg0pCzwk1NjYqHA6rsLDQ6fN6vcrPz1dNTU2Pn+no6FA0GnU1AMDQkNAQCofDkiS/3+/q9/v9zr7uSktL5fP5nJaVlZXIkgAAA1i/XB3n8Xhc28aYmL7jSkpKFIlEnNbU1NQfJQEABqCEvlk1EAhI+nJF9NW36rW0tMSsjo7zer3yer2JLAMAkCQSuhLKzs5WIBBQVVWV09fZ2anq6mrl5eUl8qsAAINA3Cuhzz//XB9++KGz3djYqLq6Oo0ZM0bjx49XUVGRQqGQcnJylJOTo1AopNTUVC1atCihhQMAkl/cIfT3v/9dP/zhD53t1atXS5IWL16sRx55RMXFxWpvb9fy5cvV2tqqWbNmqbKyUmlpaYmrGgAwKHiMMcZ2EV8VjUbl8/nU3Nys9PT0Ph3r/fffd21/8cUXfToeAAw2I0eOdG1PmjSpz8eMRqPKyMhQJBI54e9xnh0HALCGEAIAWEMIAQCsSeh9QgPNLbfc4tquq6uzUwgADFDTpk1zbb/xxhun9PtZCQEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMCauEKotLRUF154odLS0jRu3DhdddVV2rdvn2uMMUbBYFCZmZlKSUlRQUGBGhoaElo0AGBwiCuEqqurtWLFCr355puqqqrS0aNHVVhYqMOHDztjNm7cqE2bNmnz5s2qra1VIBDQ3Llz1dbWlvDiAQDJbXg8g59//nnX9vbt2zVu3Djt2bNHl1xyiYwxKisr09q1a7VgwQJJUnl5ufx+vyoqKrR06dLEVQ4ASHp9OicUiUQkSWPGjJEkNTY2KhwOq7Cw0Bnj9XqVn5+vmpqaHo/R0dGhaDTqagCAoaHXIWSM0erVqzVnzhzl5uZKksLhsCTJ7/e7xvr9fmdfd6WlpfL5fE7LysrqbUkAgCTT6xBauXKl3nvvPT322GMx+zwej2vbGBPTd1xJSYkikYjTmpqaelsSACDJxHVO6LjbbrtNu3fv1quvvqqzzz7b6Q8EApK+XBFlZGQ4/S0tLTGro+O8Xq+8Xm9vygAAJLm4VkLGGK1cuVK7du3Syy+/rOzsbNf+7OxsBQIBVVVVOX2dnZ2qrq5WXl5eYioGAAwaca2EVqxYoYqKCv3pT39SWlqac57H5/MpJSVFHo9HRUVFCoVCysnJUU5OjkKhkFJTU7Vo0aJ++QEAAMkrrhDasmWLJKmgoMDVv337dt18882SpOLiYrW3t2v58uVqbW3VrFmzVFlZqbS0tIQUDAAYPOIKIWPMCcd4PB4Fg0EFg8He1pQwEyZMcG0fOXLEUiUAMDB1/z15qvHsOACANYQQAMAaQggAYE2v7hNKFiUlJa5tzgkBgFtqaqrV72clBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYM2gvlm1+4v0Ojo6LFUCAAOT7ZeKshICAFhDCAEArCGEAADWEEIAAGsG9YUJw4cP6h8PAPrM9u9JVkIAAGsIIQCANYQQAMCaIXXSxOPx2C4BAPAVrIQAANYQQgAAawghAIA1g/qc0LBhw1zbxhhLlQDAwNT99+SpxkoIAGANIQQAsIYQAgBYQwgBAKwhhAAA1hBCAABrCCEAgDVxhdCWLVs0depUpaenKz09XRdffLGee+45Z78xRsFgUJmZmUpJSVFBQYEaGhoSXjQAYHCI62bVs88+Wxs2bNB3v/tdSVJ5ebmuvPJKvfPOO5o8ebI2btyoTZs26ZFHHtG5556r9evXa+7cudq3b5/S0tL65Qf4JoFAwLXNA0wBwK37Tfzt7e2n9Ps9po+PERgzZox+/vOfa8mSJcrMzFRRUZHWrFkjSero6JDf79cDDzygpUuXntTxotGofD6fmpublZ6e3pfSlJKS4tomhADArT9CKBqNKiMjQ5FI5IS/x3t9TujYsWPauXOnDh8+rIsvvliNjY0Kh8MqLCx0xni9XuXn56umpuZrj9PR0aFoNOpqAIChIe4Qqq+v1+jRo+X1erVs2TI99dRTOv/88xUOhyVJfr/fNd7v9zv7elJaWiqfz+e0rKyseEsCACSpuEPoe9/7nurq6vTmm2/q1ltv1eLFi7V3715nf/c/eRljvvHPYCUlJYpEIk5ramqKtyQAQJKK+ynaI0aMcC5MmDlzpmpra/WrX/3KOQ8UDoeVkZHhjG9paYlZHX2V1+uV1+uNtwwAwCDQ5/uEjDHq6OhQdna2AoGAqqqqnH2dnZ2qrq5WXl5eX78GADAIxbUSuvvuuzVv3jxlZWWpra1NO3fu1CuvvKLnn39eHo9HRUVFCoVCysnJUU5OjkKhkFJTU7Vo0aL+qh8AkMTiCqH//ve/uvHGG9Xc3Cyfz6epU6fq+eef19y5cyVJxcXFam9v1/Lly9Xa2qpZs2apsrLSyj1CAICBr8/3CSVaIu8T+vzzz13bXV1dfToeAAw2p53mPiszevToPh/zlNwnBABAXxFCAABrCCEAgDVx3yeUTLqfE+ro6LBUCQAMTN3v00zEOaF4sBICAFhDCAEArCGEAADWEEIAAGuG1IUJp/qNgQAw0HV/+eepxkoIAGANIQQAsIYQAgBYM6jPCTU0NLi2P/30U0uVAMDANHbsWNf28ZeWniqshAAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYQwgBAKwZ1DerPvroo67t7jevAsBQN3nyZNf2lVdeeUq/n5UQAMAaQggAYA0hBACwZlCfEwqHw67tpqYmS5UAwMDU/QGmpxorIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADW9CmESktL5fF4VFRU5PQZYxQMBpWZmamUlBQVFBTwzDYAQI96HUK1tbXaunWrpk6d6urfuHGjNm3apM2bN6u2tlaBQEBz585VW1tbn4sFAAwuvQqhzz//XNdff722bdumb3/7206/MUZlZWVau3atFixYoNzcXJWXl+vIkSOqqKhIWNEAgMGhVyG0YsUKzZ8/X5dddpmrv7GxUeFwWIWFhU6f1+tVfn6+ampqejxWR0eHotGoqwEAhoa4nx23c+dOvf3226qtrY3Zd/xZbX6/39Xv9/t14MCBHo9XWlqq++67L94yAACDQFwroaamJq1atUo7duzQyJEjv3acx+NxbRtjYvqOKykpUSQScRoPGQWAoSOuldCePXvU0tKiGTNmOH3Hjh3Tq6++qs2bN2vfvn2SvlwRZWRkOGNaWlpiVkfHeb1eeb3e3tQOAEhyca2ELr30UtXX16uurs5pM2fO1PXXX6+6ujpNnDhRgUBAVVVVzmc6OztVXV2tvLy8hBcPAEhuca2E0tLSlJub6+obNWqUxo4d6/QXFRUpFAopJydHOTk5CoVCSk1N1aJFixJXNQBgUEj4S+2Ki4vV3t6u5cuXq7W1VbNmzVJlZaXS0tIS/VUAgCTX5xB65ZVXXNsej0fBYFDBYLCvhwYADHI8Ow4AYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYE1cIRQMBuXxeFwtEAg4+40xCgaDyszMVEpKigoKCtTQ0JDwogEAg0PcK6HJkyerubnZafX19c6+jRs3atOmTdq8ebNqa2sVCAQ0d+5ctbW1JbRoAMDgEHcIDR8+XIFAwGlnnnmmpC9XQWVlZVq7dq0WLFig3NxclZeX68iRI6qoqEh44QCA5Bd3CH3wwQfKzMxUdna2rrvuOn300UeSpMbGRoXDYRUWFjpjvV6v8vPzVVNT87XH6+joUDQadTUAwNAQVwjNmjVLjz76qF544QVt27ZN4XBYeXl5+vTTTxUOhyVJfr/f9Rm/3+/s60lpaal8Pp/TsrKyevFjAACSUVwhNG/ePF199dWaMmWKLrvsMv35z3+WJJWXlztjPB6P6zPGmJi+ryopKVEkEnFaU1NTPCUBAJJYny7RHjVqlKZMmaIPPvjAuUqu+6qnpaUlZnX0VV6vV+np6a4GABga+hRCHR0d+uc//6mMjAxlZ2crEAioqqrK2d/Z2anq6mrl5eX1uVAAwOAzPJ7BP/vZz3TFFVdo/Pjxamlp0fr16xWNRrV48WJ5PB4VFRUpFAopJydHOTk5CoVCSk1N1aJFi/qrfgBAEosrhP7zn/9o4cKFOnTokM4880z94Ac/0JtvvqkJEyZIkoqLi9Xe3q7ly5ertbVVs2bNUmVlpdLS0vqleABAcosrhHbu3PmN+z0ej4LBoILBYF9qAgAMETw7DgBgDSEEALCGEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwBpCCABgDSEEALCGEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwBpCCABgDSEEALCGEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwBpCCABgDSEEALCGEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwBpCCABgTdwh9PHHH+uGG27Q2LFjlZqaqmnTpmnPnj3OfmOMgsGgMjMzlZKSooKCAjU0NCS0aADA4BBXCLW2tmr27Nk6/fTT9dxzz2nv3r365S9/qW9961vOmI0bN2rTpk3avHmzamtrFQgENHfuXLW1tSW6dgBAkhsez+AHHnhAWVlZ2r59u9N3zjnnOP9tjFFZWZnWrl2rBQsWSJLKy8vl9/tVUVGhpUuXJqZqAMCgENdKaPfu3Zo5c6auueYajRs3TtOnT9e2bduc/Y2NjQqHwyosLHT6vF6v8vPzVVNT0+MxOzo6FI1GXQ0AMDTEFUIfffSRtmzZopycHL3wwgtatmyZbr/9dj366KOSpHA4LEny+/2uz/n9fmdfd6WlpfL5fE7Lysrqzc8BAEhCcYVQV1eXLrjgAoVCIU2fPl1Lly7VT3/6U23ZssU1zuPxuLaNMTF9x5WUlCgSiTitqakpzh8BAJCs4gqhjIwMnX/++a6+8847TwcPHpQkBQIBSYpZ9bS0tMSsjo7zer1KT093NQDA0BBXCM2ePVv79u1z9e3fv18TJkyQJGVnZysQCKiqqsrZ39nZqerqauXl5SWgXADAYBLX1XF33HGH8vLyFAqF9OMf/1hvvfWWtm7dqq1bt0r68s9wRUVFCoVCysnJUU5OjkKhkFJTU7Vo0aJ++QEAAMkrrhC68MIL9dRTT6mkpETr1q1Tdna2ysrKdP311ztjiouL1d7eruXLl6u1tVWzZs1SZWWl0tLSEl48ACC5eYwxxnYRXxWNRuXz+dTc3Nzn80OzZ892bdfV1fXpeAAw2EybNs21/cYbb/T5mNFoVBkZGYpEIif8Pc6z4wAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYQwgBAKwhhAAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYQwgBAKwhhAAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYQwgBAKwhhAAA1hBCAABrCCEAgDWEEADAGkIIAGANIQQAsIYQAgBYQwgBAKwhhAAA1sQVQuecc448Hk9MW7FihSTJGKNgMKjMzEylpKSooKBADQ0N/VI4ACD5xRVCtbW1am5udlpVVZUk6ZprrpEkbdy4UZs2bdLmzZtVW1urQCCguXPnqq2tLfGVAwCSXlwhdOaZZyoQCDjt2Wef1Xe+8x3l5+fLGKOysjKtXbtWCxYsUG5ursrLy3XkyBFVVFT0V/0AgCTW63NCnZ2d2rFjh5YsWSKPx6PGxkaFw2EVFhY6Y7xer/Lz81VTU/O1x+no6FA0GnU1AMDQ0OsQevrpp/XZZ5/p5ptvliSFw2FJkt/vd43z+/3Ovp6UlpbK5/M5LSsrq7clAQCSTK9D6OGHH9a8efOUmZnp6vd4PK5tY0xM31eVlJQoEok4rampqbclAQCSzPDefOjAgQN68cUXtWvXLqcvEAhI+nJFlJGR4fS3tLTErI6+yuv1yuv19qYMAECS69VKaPv27Ro3bpzmz5/v9GVnZysQCDhXzElfnjeqrq5WXl5e3ysFAAw6ca+Eurq6tH37di1evFjDh///xz0ej4qKihQKhZSTk6OcnByFQiGlpqZq0aJFCS0aADA4xB1CL774og4ePKglS5bE7CsuLlZ7e7uWL1+u1tZWzZo1S5WVlUpLS0tIsQCAwSXuECosLJQxpsd9Ho9HwWBQwWCwr3UBAIYAnh0HALCGEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwBpCCABgDSEEALCGEAIAWEMIAQCsIYQAANb06qV2p0J7e7vrVRG90dXVlaBqgKGl+9uQv/ruMNveeeedmL6PP/7YQiWDw9GjR13bLS0tfT5mW1vbSY9lJQQAsIYQAgBYQwgBAKwhhAAA1gzYCxM+++wzHTt2rE/H6OvngaGq+0VBq1evtlRJrA0bNsT0cWFC73V2drq2Gxsb+3zMw4cPn/RYVkIAAGsIIQCANYQQAMCaAXtOCIA93W9gXLZsmaVKYjU3N9suAQnESggAYA0hBACwhhACAFhDCAEArPEYY4ztIr4qGo3K5/Pp6quv1umnn96nY73wwguu7dbW1j4dDwBw8iKRiNLT079xDCshAIA1hBAAwBpCCABgzYA9JwQASG6cEwIADGiEEADAmrhC6OjRo7rnnnuUnZ2tlJQUTZw4UevWrVNXV5czxhijYDCozMxMpaSkqKCgQA0NDQkvHAAwCJg4rF+/3owdO9Y8++yzprGx0TzxxBNm9OjRpqyszBmzYcMGk5aWZp588klTX19vrr32WpORkWGi0ehJfUckEjGSaDQajZbkLRKJnPB3flwhNH/+fLNkyRJX34IFC8wNN9xgjDGmq6vLBAIBs2HDBmf/F198YXw+n3nooYdO6jsIIRqNRhsc7WRCKK4/x82ZM0cvvfSS9u/fL0l699139frrr+vyyy+X9OVrYcPhsAoLC53PeL1e5efnq6ampsdjdnR0KBqNuhoAYGiI631Ca9asUSQS0aRJkzRs2DAdO3ZM999/vxYuXChJCofDkiS/3+/6nN/v14EDB3o8Zmlpqe67777e1A4ASHJxrYQef/xx7dixQxUVFXr77bdVXl6uX/ziFyovL3eN83g8rm1jTEzfcSUlJYpEIk5ramqK80cAACSruFZCd955p+666y5dd911kqQpU6bowIEDKi0t1eLFixUIBCR9uSLKyMhwPtfS0hKzOjrO6/XK6/X2tn4AQBKLayV05MgRnXaa+yPDhg1zLtHOzs5WIBBQVVWVs7+zs1PV1dXKy8tLQLkAgEHl5K+NM2bx4sXmrLPOci7R3rVrlznjjDNMcXGxM2bDhg3G5/OZXbt2mfr6erNw4UIu0abRaLQh2BJ+iXY0GjWrVq0y48ePNyNHjjQTJ040a9euNR0dHc6Yrq4uc++995pAIGC8Xq+55JJLTH19/Ul/ByFEo9Fog6OdTAjxAFMAQL/gAaYAgAGNEAIAWEMIAQCsIYQAANYQQgAAawghAIA1hBAAwJoBF0ID7LYlAEAvnczv8wEXQm1tbbZLAAAkwMn8Ph9wT0zo6urSJ598orS0NLW1tSkrK0tNTU0nvOsW8YtGo8xvP2J++xfz27/6Mr/GGLW1tSkzMzPmodfdxfUqh1PhtNNO09lnny3p/99LlJ6ezj+yfsT89i/mt38xv/2rt/N7so9fG3B/jgMADB2EEADAmgEdQl6vV/feey9vXu0nzG//Yn77F/Pbv07V/A64CxMAAEPHgF4JAQAGN0IIAGANIQQAsIYQAgBYQwgBAKwZsCH04IMPKjs7WyNHjtSMGTP02muv2S4pKZWWlurCCy9UWlqaxo0bp6uuukr79u1zjTHGKBgMKjMzUykpKSooKFBDQ4OlipNXaWmpPB6PioqKnD7mtu8+/vhj3XDDDRo7dqxSU1M1bdo07dmzx9nPHPfe0aNHdc899yg7O1spKSmaOHGi1q1bp66uLmdMv8+vGYB27txpTj/9dLNt2zazd+9es2rVKjNq1Chz4MAB26UlnR/96Edm+/bt5h//+Iepq6sz8+fPN+PHjzeff/65M2bDhg0mLS3NPPnkk6a+vt5ce+21JiMjw0SjUYuVJ5e33nrLnHPOOWbq1Klm1apVTj9z2zf/+9//zIQJE8zNN99s/va3v5nGxkbz4osvmg8//NAZwxz33vr1683YsWPNs88+axobG80TTzxhRo8ebcrKypwx/T2/AzKELrroIrNs2TJX36RJk8xdd91lqaLBo6WlxUgy1dXVxhhjurq6TCAQMBs2bHDGfPHFF8bn85mHHnrIVplJpa2tzeTk5JiqqiqTn5/vhBBz23dr1qwxc+bM+dr9zHHfzJ8/3yxZssTVt2DBAnPDDTcYY07N/A64P8d1dnZqz549KiwsdPUXFhaqpqbGUlWDRyQSkSSNGTNGktTY2KhwOOyab6/Xq/z8fOb7JK1YsULz58/XZZdd5upnbvtu9+7dmjlzpq655hqNGzdO06dP17Zt25z9zHHfzJkzRy+99JL2798vSXr33Xf1+uuv6/LLL5d0auZ3wD1F+9ChQzp27Jj8fr+r3+/3KxwOW6pqcDDGaPXq1ZozZ45yc3MlyZnTnub7wIEDp7zGZLNz5069/fbbqq2tjdnH3PbdRx99pC1btmj16tW6++679dZbb+n222+X1+vVTTfdxBz30Zo1axSJRDRp0iQNGzZMx44d0/3336+FCxdKOjX/hgdcCB13/DUOxxljYvoQn5UrV+q9997T66+/HrOP+Y5fU1OTVq1apcrKSo0cOfJrxzG3vdfV1aWZM2cqFApJkqZPn66GhgZt2bJFN910kzOOOe6dxx9/XDt27FBFRYUmT56suro6FRUVKTMzU4sXL3bG9ef8Drg/x51xxhkaNmxYzKqnpaUlJo1x8m677Tbt3r1bf/3rX533NUlSIBCQJOa7F/bs2aOWlhbNmDFDw4cP1/Dhw1VdXa1f//rXGj58uDN/zG3vZWRk6Pzzz3f1nXfeeTp48KAk/v321Z133qm77rpL1113naZMmaIbb7xRd9xxh0pLSyWdmvkdcCE0YsQIzZgxQ1VVVa7+qqoq5eXlWaoqeRljtHLlSu3atUsvv/yysrOzXfuzs7MVCARc893Z2anq6mrm+wQuvfRS1dfXq66uzmkzZ87U9ddfr7q6Ok2cOJG57aPZs2fH3FKwf/9+TZgwQRL/fvvqyJEjMW8+HTZsmHOJ9imZ34Rc3pBgxy/Rfvjhh83evXtNUVGRGTVqlPn3v/9tu7Skc+uttxqfz2deeeUV09zc7LQjR444YzZs2GB8Pp/ZtWuXqa+vNwsXLuQS11766tVxxjC3ffXWW2+Z4cOHm/vvv9988MEH5g9/+INJTU01O3bscMYwx723ePFic9ZZZzmXaO/atcucccYZpri42BnT3/M7IEPIGGN++9vfmgkTJpgRI0aYCy64wLmkGPGR1GPbvn27M6arq8vce++9JhAIGK/Xay655BJTX19vr+gk1j2EmNu+e+aZZ0xubq7xer1m0qRJZuvWra79zHHvRaNRs2rVKjN+/HgzcuRIM3HiRLN27VrT0dHhjOnv+eV9QgAAawbcOSEAwNBBCAEArCGEAADWEEIAAGsIIQCANYQQAMAaQggAYA0hBACwhhACAFhDCAEArCGEAADW/B8DizQqrTnvYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with total reward: 0\n"
     ]
    }
   ],
   "source": [
    "# https://ale.farama.org/environments/breakout/\n",
    "ENV_NAME = \"ALE/Breakout-v5\" \n",
    "\n",
    "env = make_env(ENV_NAME,\n",
    "                video_folder='./videos/random',\n",
    "                name_prefix=\"breakout\",\n",
    "                record_every=None,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES\n",
    "                )\n",
    "\n",
    "for episode_num in range(1):\n",
    "    obs, info = env.reset()\n",
    "    show_observation_stack(obs)\n",
    "    reward_total = 0\n",
    "    episode_over = False\n",
    "    while not episode_over:\n",
    "        action = env.action_space.sample()  # seleccionamos una acción aleatoria\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        reward_total += reward\n",
    "        episode_over = terminated or truncated\n",
    "    print(f\"Episode {episode_num + 1} finished with total reward: {reward_total}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, podemos mostrar los videos capturados por el entorno de Atari de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls  width=\"600\" >\n",
       " <source src=\"data:None;base64,./videos/random/breakout-episode-0.mp4\" type=\"None\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta al archivo de vídeo en tu sistema de ficheros\n",
    "video_path = \"./videos/random/breakout-episode-0.mp4\"\n",
    "\n",
    "# Muestra el vídeo\n",
    "Video(video_path, embed=True, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bYVG_TKt9I5"
   },
   "source": [
    "# Exploración del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions shape: Discrete(4)\n",
      "Observation shape: (4, 84, 84)\n",
      "(4, 84, 84),\n",
      " 0,\n",
      " False,\n",
      " {'lives': 5, 'episode_frame_number': 11, 'frame_number': 546}\n"
     ]
    }
   ],
   "source": [
    "print(\"Actions shape:\",env.action_space)\n",
    "print(\"Observation shape:\",env.observation_space.shape)\n",
    "env.reset()\n",
    "next_state, reward, terminated, truncated, info = env.step(action=0)\n",
    "\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {terminated},\\n {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIHpwiaat9I7"
   },
   "source": [
    "# Deep Q Learning\n",
    "\n",
    "Deep Q Learning extiende el algoritmo clásico de Q-learning al emplear una **red neuronal profunda** como aproximador de la función de valor $Q(s,a)$. Inspirado en Mnih et al. (2013), este método utiliza una **red convolucional** para procesar directamente las imágenes del entorno Atari, un **replay buffer** para romper la correlación temporal de las muestras. La política sigue un esquema **ε-greedy**, balanceando exploración y explotación, y se entrena minimizando el error de la ecuación de Bellman sobre lotes de transiciones muestreadas de manera aleatoria.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.researchgate.net/profile/Faris-Mismar/publication/327045314/figure/fig4/AS:819677282455553@1572437701142/Structure-of-the-neural-network-used-for-the-Deep-Q-learning-Network-implementation-with.png\" alt=\"DQN\"/>\n",
    "</p>\n",
    "\n",
    "Fuente: [arXiv:1312.5602](https://arxiv.org/abs/1312.5602)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajTGajUftSgY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Memoria\n",
    "\n",
    "El algoritmo de Deep Q Learning presentado en el paper utiliza una memoria (llamada Replay Memory) para almacenar transiciones pasadas. Tuplas que contienen un estado base, la accion tomada, la recompensa obtenida, una bandera que indica si el siguiente estado es final o no; y el estado siguiente.\n",
    "\n",
    "Esta memoria es circular, es decir, tiene un límite maximo de elementos y una vez esté llena comienza a reemplazar los elementos más viejos.\n",
    "\n",
    "Vamos a necesitar crear una función **sample** que obtiene una mustra aleatoria de elementos de la memoria.  Esto puede ser una lista de Transiciones o listas separadas (pero alineadas) de los elementos que las componen.\n",
    "\n",
    "\n",
    "> Para implementar esta funcionalidad se debe modificar el archivo **replay_memory.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "scPtpbz4tTAh",
    "outputId": "0890f48a-e673-4416-bd69-7dcf2730ba64",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size: 3\n",
      "\n",
      "Sate shape: torch.Size([4, 84, 84])\n",
      "Action shape: torch.Size([1])\n",
      "Reward shape: torch.Size([1])\n",
      "Done shape: torch.Size([1])\n",
      "Next state shape: torch.Size([4, 84, 84])\n",
      "Memory sample:\n",
      "Sample 0: Transition(state=tensor([[[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]]]), action=tensor([1]), reward=tensor([10.]), done=tensor([0.]), next_state=tensor([[[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
      "\n",
      "        [[0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         ...,\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]]]))\n",
      "Sample 1: Transition(state=tensor([[[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]]]), action=tensor([3]), reward=tensor([10.]), done=tensor([1.]), next_state=tensor([[[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "\n",
      "        [[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]]]))\n",
      "Sample 2: Transition(state=tensor([[[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]]]), action=tensor([2]), reward=tensor([10.]), done=tensor([0.]), next_state=tensor([[[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],\n",
      "\n",
      "        [[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]]]))\n"
     ]
    }
   ],
   "source": [
    "import replay_memory \n",
    "from replay_memory import ReplayMemory, Transition\n",
    "import importlib\n",
    "importlib.reload(replay_memory)\n",
    "\n",
    "# Creamos la memoria de repetición\n",
    "replay_memory = ReplayMemory(3, lambda obs,device:torch.tensor(obs, dtype=torch.float32, device=device) / 255.0)\n",
    "\n",
    "# Añadimos transiciones a la memoria (solo las 3 últimas se guardan)\n",
    "replay_memory.add(np.ones((4,84,84)), 0, 10, False, np.ones((4,84,84)))\n",
    "replay_memory.add(np.ones((4,84,84))*2, 1, 10, False, np.ones((4,84,84))*2)\n",
    "replay_memory.add(np.ones((4,84,84))*3, 2, 10, False, np.ones((4,84,84))*3)\n",
    "replay_memory.add(np.ones((4,84,84))*4, 3, 10, True, np.ones((4,84,84))*4)\n",
    "\n",
    "# Mostramos el tamaño de la memoria\n",
    "print(f\"Memory size: {len(replay_memory)}\\n\")\n",
    "\n",
    "# Sampleamos 3 transiciones de la memoria\n",
    "sampled_transition = replay_memory.sample(3)\n",
    "\n",
    "# Comprobamos los shapes de los datos\n",
    "(state, action, reward, done, next_state) = sampled_transition[0]\n",
    "print(\"Sate shape:\", state.shape)\n",
    "print(\"Action shape:\", action.shape)\n",
    "print(\"Reward shape:\", reward.shape)\n",
    "print(\"Done shape:\", done.shape)\n",
    "print(\"Next state shape:\", next_state.shape)\n",
    "\n",
    "# Mostramos un sample de la memoria\n",
    "print(f\"Memory sample:\")\n",
    "for i, sample in enumerate(sampled_transition):\n",
    "    print(f\"Sample {i}: {sample}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7Ygv5Mjtb-F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modelo\n",
    "\n",
    "Vamos a usar un mismo modelo FeedForward para estos dos problemas (entrenado en cada problema particular). Recomendamos simplicidad en la creación del mismo, pero tienen total libertad al momento de implementarlo.\n",
    "\n",
    "> Para implementar esta funcionalidad se debe modificar el archivo **dqn_cnn_model.py**. Se recomienda empezar por una arquitectura simple como la que se muestra en el paper de Mnih et al. (2013) y luego experimentar con arquitecturas más complejas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bkNBvJB6ryp7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions shape: Discrete(4)\n",
      "Observatiion shape: (4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DQN_CNN_Model                            [32, 4]                   --\n",
       "├─Conv2d: 1-1                            [32, 16, 20, 20]          4,112\n",
       "├─Conv2d: 1-2                            [32, 32, 9, 9]            8,224\n",
       "├─Linear: 1-3                            [32, 256]                 663,808\n",
       "├─Linear: 1-4                            [32, 4]                   1,028\n",
       "==========================================================================================\n",
       "Total params: 677,172\n",
       "Trainable params: 677,172\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 95.22\n",
       "==========================================================================================\n",
       "Input size (MB): 3.61\n",
       "Forward/backward pass size (MB): 2.37\n",
       "Params size (MB): 2.71\n",
       "Estimated Total Size (MB): 8.69\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dqn_cnn_model import DQN_CNN_Model\n",
    "\n",
    "env = make_env(ENV_NAME,\n",
    "                record_every=None,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES\n",
    "                )\n",
    "print(\"Actions shape:\",env.action_space)\n",
    "print(\"Observatiion shape:\",env.observation_space.shape)\n",
    "\n",
    "env.close()\n",
    "\n",
    "cnn_model = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "summary(cnn_model, input_size=(32, SKIP_FRAMES, SCREEN_SIZE, SCREEN_SIZE), device=DEVICE) # 32 es el batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red esta definida para que reciba un tensor de 4 dimensiones (batch_size, num_frames, height, width) y devuelve un tensor de 2 dimensiones (batch_size, num_actions). La función `forward` es la encargada de definir el flujo de datos a través de la red. En este caso, se utiliza una red convolucional seguida de capas totalmente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-values shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "obs_tensor_batch = torch.rand((NUM_STACKED_FRAMES,SCREEN_SIZE,SCREEN_SIZE)).unsqueeze(0).to(DEVICE) # Añadimos una dimensión para el batch y lo pasamos al dispositivo\n",
    "print(f\"Q-values shape: {cnn_model(obs_tensor_batch).shape}\") # shape: (1, num_actions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de Q se obtienen a partir de la salida de la red, cada columna representa el valor Q para cada acción posible en el estado actual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0188,  0.0008,  0.0328,  0.0380]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model(obs_tensor_batch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos preguntar cuál es la acción con mayor valor Q en un estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0380], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([3], device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model(obs_tensor_batch).max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo vamos a ver cómo tomar los valores de acciones deseables para un conjunto de estados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([3, 4, 84, 84])\n",
      "Q-values: tensor([[-0.0399,  0.0014,  0.0332,  0.0316],\n",
      "        [-0.0319,  0.0112,  0.0292,  0.0156],\n",
      "        [-0.0356,  0.0033,  0.0296,  0.0224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Q-values: tensor([[0.0014],\n",
      "        [0.0292],\n",
      "        [0.0224]], device='cuda:0', grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Creamos 3 observaciones aleatorias para probar el modelo\n",
    "obs_ran1 = torch.rand(4, 84, 84)\n",
    "obs_ran2 = torch.rand(4, 84, 84)\n",
    "obs_ran3 = torch.rand(4, 84, 84)\n",
    "\n",
    "batch = torch.stack([obs_ran1, obs_ran2, obs_ran3], dim=0).to(DEVICE) # shape: (3, 4, 84, 84)\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "\n",
    "actions =  torch.tensor([1, 2, 3], device=DEVICE).unsqueeze(1) # queremos la acción 1 para la primera observación, la acción 2 para la segunda y la acción 3 para la tercera\n",
    "\n",
    "Q_test = cnn_model(batch)\n",
    "print(f\"Q-values: {Q_test}\")\n",
    "print(f\"Q-values: {Q_test.gather(1, actions)}\") # https://pytorch.org/docs/main/generated/torch.gather.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi \n",
    "\n",
    "La función para procesar los estados (phi en el paper) que es necesaria para poder usar el modelo de Pytorch con las representaciones de gym. Esta función pasa una observación de gym a un tensor de Pytorch y la normaliza.\n",
    "\n",
    "> Técnicamente la función phi tiene más responsabilidades, como la de apilar los frames y el downsampling. En nuestro caso se lo delegamos a los wrappers de gymnasium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oegpMg25t9I9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation shape: torch.Size([4, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "def process_state(obs, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Preprocess the state to be used as input for the model (transform to tensor).\n",
    "    \"\"\"\n",
    "    return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0\n",
    "\n",
    "obs, _ = env.reset()\n",
    "obs_tensor = process_state(obs)\n",
    "print(f\"Observation shape: {obs_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9B7ZY9Htj_F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Agente\n",
    "\n",
    "Vamos a definir una clase agente (abstracto), encargado de interactuar con el ambiente y entrenar los modelos. Los métdos definidos deben funcionar para ambos problemas simplemente cambiando el modelo a utilizar para cada ambiente.\n",
    "\n",
    "Abajo dejamos un esqueleto del mismo y las funciones a completar. Recomendamos no alterar la estructura del mismo, pero pueden definir las funciones auxiliares que consideren necesarias.\n",
    "\n",
    "> Para implementar esta funcionalidad se debe modificar los archivos **abstract_agent.py** y **dqn_agent.py**.\n",
    "\n",
    "Funciones a completar:\n",
    "\n",
    "\n",
    "1. **init**: que inicializa los parametros del agente.\n",
    "\n",
    "2. **compute_epsilon**: que computa el valor actual de epsilon en base al número de pasos actuales y si esta entrenando o no.\n",
    "\n",
    "3. **select_action**: Seleccionando acciones \"epsilongreedy-mente\" si estamos entranando y completamente greedy en otro caso.\n",
    "\n",
    "4. **train**: que entrena el agente por un número dado de episodios de largo determinado.\n",
    "\n",
    "5. **record_test_episode**: para grabar un episodio con el agente siempre seleccionando la mejor accion conocida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOD-ENZRtyMt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparámetros de entrenamiento del agente DQN\n",
    "TOTAL_STEPS = 10_000_000\n",
    "EPISODES = 10\n",
    "STEPS_PER_EPISODE = 20_000\n",
    "\n",
    "EPSILON_INI = 1\n",
    "EPSILON_MIN = 0.05\n",
    "EPSILON_ANNEAL_STEPS = 1_000_000\n",
    "\n",
    "EPISODE_BLOCK = 100\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 50_000\n",
    "\n",
    "GAMMA = 0.995\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BsTl-pFqt10b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:  10%|█         | 1/10 [00:01<00:12,  1.37s/episode, reward=0, epsilon=1, steps=139]\n"
     ]
    }
   ],
   "source": [
    "import dqn_agent\n",
    "from dqn_agent import DQNAgent\n",
    "importlib.reload(dqn_agent)\n",
    "\n",
    "env = make_env(ENV_NAME,\n",
    "                video_folder='./videos/dqn_training',\n",
    "                name_prefix=\"breakout\",\n",
    "                record_every=500,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES\n",
    "                )\n",
    "\n",
    "net = DQN_CNN_Model(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "dqn_agent = DQNAgent(env, net, process_state, BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, epsilon_i=EPSILON_INI, epsilon_f=EPSILON_MIN, epsilon_anneal_steps=EPSILON_ANNEAL_STEPS, episode_block=EPISODE_BLOCK, device=DEVICE)\n",
    "\n",
    "dqn_rewards = dqn_agent.train(EPISODES, STEPS_PER_EPISODE, TOTAL_STEPS)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m env = make_env(ENV_NAME,\n\u001b[32m      2\u001b[39m                 video_folder=\u001b[33m'\u001b[39m\u001b[33m./videos/dqn_validation\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m                 name_prefix=\u001b[33m\"\u001b[39m\u001b[33mbreakout\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m                 skip_frames=SKIP_FRAMES\n\u001b[32m      9\u001b[39m                 )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mdqn_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m env.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\Dropbox\\maestria\\workspace\\taller_ia\\obligatorio\\abstract_agent.py:99\u001b[39m, in \u001b[36mAgent.play\u001b[39m\u001b[34m(self, env, episodes)\u001b[39m\n\u001b[32m     97\u001b[39m current_episode_steps = \u001b[32m0\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     action = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_episode_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     next_state, _, terminated, truncated, _ = env.step(action)\n\u001b[32m    101\u001b[39m     state = next_state \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\Dropbox\\maestria\\workspace\\taller_ia\\obligatorio\\dqn_agent.py:26\u001b[39m, in \u001b[36mDQNAgent.select_action\u001b[39m\u001b[34m(self, state, current_steps, train)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     25\u001b[39m   phi_state = \u001b[38;5;28mself\u001b[39m.state_processing_function(state).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m   q = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m   action = torch.argmax(q, dim=\u001b[32m1\u001b[39m).item()\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\Dropbox\\maestria\\workspace\\taller_ia\\obligatorio\\dqn_cnn_model.py:55\u001b[39m, in \u001b[36mDQN_CNN_Model.forward\u001b[39m\u001b[34m(self, obs)\u001b[39m\n\u001b[32m     53\u001b[39m result = F.relu(result)                         \u001b[38;5;66;03m#and applies a rectifier nonlinearity\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m#ReLU1 output shape: (batch_size, 16, 20, 20)               \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m                     \u001b[38;5;66;03m#The second hidden layer convolves 32 4 × 4 filters with stride 2               \u001b[39;00m\n\u001b[32m     56\u001b[39m  \u001b[38;5;66;03m#Conv2 output shape: (batch_size, 32, 9, 9)          \u001b[39;00m\n\u001b[32m     57\u001b[39m result = F.relu(result)                         \u001b[38;5;66;03m#again followed by a rectifier nonlinearity   \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clean\\miniconda3\\envs\\obl_taller_ia\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "env = make_env(ENV_NAME,\n",
    "                video_folder='./videos/dqn_validation',\n",
    "                name_prefix=\"breakout\",\n",
    "                record_every=1,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES\n",
    "                )\n",
    "\n",
    "dqn_agent.play(env, episodes=3)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo de vídeo en tu sistema de ficheros\n",
    "video_path = \"./videos/dqn_validation/breakout-episode-0.mp4\"\n",
    "\n",
    "# Muestra el vídeo\n",
    "Video(video_path, embed=True, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficas \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QETh1K7pt9I_"
   },
   "source": [
    "# Double Deep Q Learning\n",
    "\n",
    "Double DQN mejora la versión clásica de DQN corrigiendo el sesgo de sobreestimación de los valores \n",
    "𝑄\n",
    "Q. Para ello, desacopla la selección de la acción de su evaluación: en cada paso, la red online elige la acción que maximiza \n",
    "𝑄\n",
    "Q, pero la red objetivo distinta estima el valor de esa acción. Esta separación reduce el sesgo hacia valores demasiado optimistas y aporta mayor estabilidad al entrenamiento. El resto de la estructura —replay buffer, política ε-greedy, etc— se mantiene igual que en DQN, aprovechando así un diseño casi idéntico al original pero con resultados más fiables .\n",
    "\n",
    "Fuente: [arXiv:1509.06461](https://arxiv.org/abs/1509.06461)\n",
    "\n",
    "> Vamos a utilizar el mismo modelo de red neuronal creado para el problema anterior y la misma implementación de memoria, dejamos un esqueleto de un agente de Double Deep Q learning para completar en el archivo **double_dqn_agent.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kDNkAtdMt9I_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:  10%|█         | 1/10 [00:00<00:06,  1.36episode/s, reward=0, epsilon=1, steps=137]\n"
     ]
    }
   ],
   "source": [
    "import double_dqn_agent\n",
    "from double_dqn_agent import DoubleDQNAgent\n",
    "importlib.reload(double_dqn_agent)\n",
    "\n",
    "env = make_env(ENV_NAME,\n",
    "                video_folder='./videos/ddqn_training',\n",
    "                name_prefix=\"breakout\",\n",
    "                record_every=500,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES)\n",
    "\n",
    "\n",
    "modelo_a = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "modelo_b = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "\n",
    "ddqn_agent = DoubleDQNAgent(env, modelo_a, modelo_b, process_state, BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, epsilon_i= EPSILON_INI, epsilon_f=EPSILON_MIN, epsilon_anneal_steps=EPSILON_ANNEAL_STEPS, episode_block = EPISODE_BLOCK, device=DEVICE)\n",
    "\n",
    "ddqn_rewards = ddqn_agent.train(EPISODES, STEPS_PER_EPISODE, TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(ENV_NAME,\n",
    "                video_folder='./videos/ddqn_validation',\n",
    "                name_prefix=\"breakout\",\n",
    "                record_every=1,\n",
    "                grayscale=GRAY_SCALE,\n",
    "                screen_size=SCREEN_SIZE,\n",
    "                stack_frames=NUM_STACKED_FRAMES,\n",
    "                skip_frames=SKIP_FRAMES\n",
    "                )\n",
    "\n",
    "ddqn_agent.play(env, episodes=3)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo de vídeo en tu sistema de ficheros\n",
    "video_path = \"./videos/ddqn_validation/breakout-episode-0.mp4\"\n",
    "\n",
    "# Muestra el vídeo\n",
    "Video(video_path, embed=True, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficas \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación\n",
    "Aquí con libertad total, pueden probar diferentes arquitecturas de red, diferentes hiperparámetros, diferentes técnicas de exploración, etc.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNNvsKiEt9I_"
   },
   "source": [
    "# Comparaciones, Resultados, Comentarios...\n",
    "De aquí en adelante son libres de presentar como gusten los resultados comparativos de las técnicas.\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "obl_taller_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
